{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, write and show an image\n",
    "To read an image, you can use the function imread. The first parameter corresponds to the path leading to the image, the second parameter is optional and determine the mode to open the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../assets/img.png', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:\n",
    "- IMREAD_COLOR convert the image to the 3 channel BGR color image\n",
    "- IMREAD_GRAYSCALE convert the image to the single channel grayscale image\n",
    "- IMREAD_UNCHANGED return the loaded image as is (with alpha channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *imshow* open a window with the image. To avoid the window to close immediately, OpenCV can wait for a keypress with *waitKey*. It is possible to specify which key in the parameter of the function. Then it is needed to explicitly close the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('My image', img)\n",
    "cv2.waitKey(0) # Will close after any input\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *imwrite* allows to write an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../assets/new_img.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image can be rotated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be resized using *resize*. The first parameter is the image, the second is the desired size of the new image, and fx and fy can be used to change the size using a ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (0, 0), fx=0.5, fy=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('My image', img)\n",
    "cv2.waitKey(0) # Will close after any input\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../assets/img.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "print(img)\n",
    "print(\"Type:\", type(img))\n",
    "print(\"Shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image consists of a matrix of three dimensions : Rows, Columns, Channels\n",
    "\n",
    "It is important to notice that OpenCV is not using the channels order as RGB but BGR.\n",
    "\n",
    "Here, the image is a numpy array. That we can easily modify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): # The first 100 lines\n",
    "    for j in range(img.shape[1]): # All columns\n",
    "        img[i][j] = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "\n",
    "cv2.imshow('Image with random values', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also take a part of the image and duplicate it somewhere else on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = img[150:200, 70:100]\n",
    "img[0:50, 150:180] = tag\n",
    "\n",
    "cv2.imshow('Image with random values', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cameras and Video Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can capture from your camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # 0 corresponds to the camera number if you have several"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../assets/vid.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using a while loop, we can get the next frame and display it in a new window. The loop will stop once we press the key 'q'.\n",
    "At the end it is important to release the resource of the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    retval, frame = cap.read() # retval is not used here but shows if something wrong is happening\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to modify the image captured and then display it with the modification.\n",
    "\n",
    "In the next example we get the next frame, transform the dimension by half and duplicate it four times on the window. For the picture at the bottom-left and the one at the top-right, we apply a rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    width = int(cap.get(3)) # 3 == width (values by default are floating point)\n",
    "    height = int(cap.get(4))# 4 == height\n",
    "\n",
    "    image = np.zeros(frame.shape, np.uint8) \n",
    "    smaller_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    image[:height//2, :width//2] = smaller_frame # Top left\n",
    "    image[height//2:, :width//2] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180) # Bottom left\n",
    "    image[:height//2, width//2:] = cv2.rotate(smaller_frame, cv2.cv2.ROTATE_180) # Top right\n",
    "    image[height//2:, width//2:] = smaller_frame # Bottom right\n",
    "\n",
    "    cv2.imshow('frame', image)\n",
    "\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line\n",
    "Syntax: cv2.line(image, start_point, end_point, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "\n",
    "    # Drawing a line\n",
    "    img = cv2.line(frame, (0,0), (width, height), (255, 0, 0), 10)\n",
    "    img = cv2.line(img, (width,0), (0, height), (0, 255, 0), 5)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle\n",
    "cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "Thickness of -1 px will fill the rectangle shape by the specified color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Drawing a rectangle\n",
    "    img = cv2.rectangle(frame, (100, 100), (200, 200), (128, 128, 128), 5)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle\n",
    "cv2.circle(image, center_coordinates, radius, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Drawing a circle\n",
    "    img = cv2.circle(frame, (300, 300), 60, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text\n",
    "cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType]])\n",
    "\n",
    "The origin org is not at the top left as for the coordinates in OpenCV, in this case it is at the bottom left.\n",
    "\n",
    "The documentation is saying that the lineType cv2.LINE_AA makes the text look better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    height = int(cap.get(4))\n",
    "\n",
    "    # Drawing a text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    img = cv2.putText(frame, 'Hello world!', (10, height - 10), font, 2, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors and Color Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to convert our BGR image into HSV (Hue Saturation Value/Brightness). The reason is because the method we will use to extract a color from an image requires an HSV image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the HSV image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "    \n",
    "    # convert an image from one color space to another\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cv2.imshow('frame', hsv)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pick a lower bound and upper bound for the color we want to extract.\n",
    "\n",
    "You can use a color picker to find the values of HSV.\n",
    "\n",
    "We then apply a mask on the image to black out each pixel not in the HSV range, and change the pixel in the range into white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow('frame', result)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to display the mask with:\n",
    "\n",
    "cv2.imshow('mask', mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corner detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time edge detection algorithms work better with gray scale images.\n",
    "\n",
    "*cv2.goodFeaturesToTrack(img, N, quality, distance)* will find corners in the gray scale image.\n",
    "It finds N strongest corners in the image by Shi-Tomasi method. Then you specify the quality level, which is a value between 0-1, which denotes the minimum quality of corner below which everyone is rejected. Then we provide the minimum euclidean distance between corners detected.\n",
    "\n",
    "We got the corners position as floating points values, we need to convert them into integer values in order to use them on the picture: *corners = np.int0(corners)*\n",
    "\n",
    "We can then draw circle at each corners and draw lines between each of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('assets/chessboard.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    cv2.circle(img, (x, y), 5, (255, 0, 0), -1)\n",
    "\n",
    "# Drawing lines between the corners\n",
    "for i in range(len(corners)):\n",
    "    for j in range(i +1, len(corners)):\n",
    "        corner1 = tuple(corners[i][0])\n",
    "        corner2 = tuple(corners[j][0])\n",
    "        color = tuple(map(lambda x : int(x), np.random.randint(0, 255, size=3)))\n",
    "        cv2.line(img, corner1, corner2, color, 1)\n",
    "\n",
    "cv2.imshow('Frame', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
